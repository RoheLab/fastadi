<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>CitationImpute — citation_impute • fastadi</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/paper/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="CitationImpute — citation_impute" />
<meta property="og:description" content="An implementation of the AdaptiveImpute algorithm using efficient
sparse matrix computations, specialized for the case when missing
values in the upper triangle are taken to be explicitly observed
zeros, as opposed to missing values. This is primarily
useful for spectral decompositions of adjacency matrices of graphs
with (near) tree structure, such as citation networks." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">fastadi</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="Unreleased version">0.0.0.9016</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/adaptive-impute.html">An introduction to AdaptiveInitialize and AdaptiveImpute</a>
    </li>
    <li>
      <a href="../articles/efficient-sparse-computation.html">Using memory-efficient sparse computations</a>
    </li>
    <li>
      <a href="../articles/sparse-matrix-intro.html">Introduction to sparse computations</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/RoheLab/fastadi/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>CitationImpute</h1>
    <small class="dont-index">Source: <a href='https://github.com/RoheLab/fastadi/blob/master/R/citation-impute.R'><code>R/citation-impute.R</code></a></small>
    <div class="hidden name"><code>citation_impute.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>An implementation of the <code>AdaptiveImpute</code> algorithm using efficient
sparse matrix computations, specialized for the case when missing
values in the upper triangle are taken to be <em>explicitly observed</em>
zeros, as opposed to missing values. This is primarily
useful for spectral decompositions of adjacency matrices of graphs
with (near) tree structure, such as citation networks.</p>
    </div>

    <pre class="usage"><span class='fu'>citation_impute</span><span class='op'>(</span>
  <span class='va'>X</span>,
  <span class='va'>rank</span>,
  <span class='va'>...</span>,
  initialization <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"svd"</span>, <span class='st'>"adaptive-initialize"</span>, <span class='st'>"approximate"</span><span class='op'>)</span>,
  max_iter <span class='op'>=</span> <span class='fl'>200L</span>,
  check_interval <span class='op'>=</span> <span class='fl'>1L</span>,
  epsilon <span class='op'>=</span> <span class='fl'>1e-07</span>,
  additional <span class='op'>=</span> <span class='cn'>NULL</span>
<span class='op'>)</span>

<span class='co'># S3 method for sparseMatrix</span>
<span class='fu'>citation_impute</span><span class='op'>(</span>
  <span class='va'>X</span>,
  <span class='va'>rank</span>,
  <span class='va'>...</span>,
  initialization <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"svd"</span>, <span class='st'>"adaptive-initialize"</span>, <span class='st'>"approximate"</span><span class='op'>)</span>,
  additional <span class='op'>=</span> <span class='cn'>NULL</span>
<span class='op'>)</span>

<span class='co'># S3 method for LRMF</span>
<span class='fu'>citation_impute</span><span class='op'>(</span>
  <span class='va'>X</span>,
  <span class='va'>rank</span>,
  <span class='va'>...</span>,
  epsilon <span class='op'>=</span> <span class='fl'>1e-07</span>,
  max_iter <span class='op'>=</span> <span class='fl'>200L</span>,
  check_interval <span class='op'>=</span> <span class='fl'>1L</span>
<span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>X</th>
      <td><p>A <em>square</em> sparse matrix of <code><a href='https://rdrr.io/pkg/Matrix/man/sparseMatrix.html'>Matrix::sparseMatrix()</a></code> class.
Implicit zeros in the upper triangle of this matrix are considered
observed and predictions on these elements contribute to the
objective function minimized by <code>AdaptiveImpute</code>.</p></td>
    </tr>
    <tr>
      <th>rank</th>
      <td><p>Desired rank (integer) to use in the low rank approximation.
Must be at least <code>2L</code> and at most the rank of <code>X</code>. Note that the rank
of <code>X</code> is typically unobserved and computations may be unstable or
even fail when <code>rank</code> is near or exceeds this threshold.</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>Unused additional arguments.</p></td>
    </tr>
    <tr>
      <th>initialization</th>
      <td><p>How to initialize the low rank approximation.
Options are:</p><ul>
<li><p><code>"svd"</code> (default). In the initialization step, this treats
unobserved values as zeroes.</p></li>
<li><p><code>"adaptive-initialize"</code>. In the initialization step, this treats
unobserved values as actually unobserved. However, the current
<code>AdaptiveInitialize</code> implementation relies on dense matrix
computations that are only suitable for relatively small matrices.</p></li>
<li><p><code>"approximate"</code>. An approximate variant of <code>AdaptiveInitialize</code>
that is less computationally expensive. See <code>adaptive_initialize</code>
for details.</p></li>
</ul>

<p>Note that initialization matters as <code>AdaptiveImpute</code> optimizes
a non-convex objective. The current theory shows that initializing
with <code>AdaptiveInitialize</code> leads to a consistent estimator, but it
isn't know if this is the case for SVD initialization. Empirically
we have found that SVD initialization works well nonetheless.</p></td>
    </tr>
    <tr>
      <th>max_iter</th>
      <td><p>Maximum number of iterations to perform (integer). Defaults
to <code>200L</code>. In practice 10 or so iterations will get you a decent
approximation to use in exploratory analysis, and and 50-100 will get
you most of the way to convergence. Must be at least <code>1L</code>.</p></td>
    </tr>
    <tr>
      <th>check_interval</th>
      <td><p>Integer specifying how often to perform convergence
checks. Defaults to <code>1L</code>. In practice, check for convergence requires
a norm calculation that is expensive for large matrices and decreasing
the frequency of convergence checks will reduce computation time. Can
also be set to <code>NULL</code>, which case <code>max_iter</code> iterations of the algorithm
will occur with no possibility of stopping due to small relative change
in the imputed matrix. In this case <code>delta</code> will be reported as <code>Inf</code>.</p></td>
    </tr>
    <tr>
      <th>epsilon</th>
      <td><p>Convergence criteria, measured in terms of relative change
in Frobenius norm of the full imputed matrix. Defaults to <code>1e-7</code>.</p></td>
    </tr>
    <tr>
      <th>additional</th>
      <td><p>Ignored except when <code>alpha_method = "approximate"</code>
in which case it controls the precise of the approximation to <code>alpha</code>.
The approximate computation of <code>alpha</code> will always understand <code>alpha</code>,
but the approximation will be better for larger values of <code>additional</code>.
We recommend making <code>additional</code> as large as computationally tolerable.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A low rank matrix factorization represented by an
<code><a href='adaptive_imputation.html'>adaptive_imputation()</a></code> object.</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'>
<span class='co'># create a (binary) square sparse matrix to demonstrate on</span>

<span class='va'>n</span> <span class='op'>&lt;-</span> <span class='fl'>100</span>
<span class='va'>A</span> <span class='op'>&lt;-</span> <span class='fu'>rsparsematrix</span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>n</span>, <span class='fl'>0.1</span>, rand.x <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span>

<span class='co'>### SVD initialization (default) --------------------------------------------</span>

<span class='va'>mf</span> <span class='op'>&lt;-</span> <span class='fu'>citation_impute</span><span class='op'>(</span><span class='va'>A</span>, rank <span class='op'>=</span> <span class='fl'>3L</span>, max_iter <span class='op'>=</span> <span class='fl'>10L</span><span class='op'>)</span>
</div><div class='output co'>#&gt; INFO [2020-10-21 02:08:05] Matrix has 1000 non-zero elements, 510 in the upper triangle (including the diagonal), and 490 in the strict lower triangle.
#&gt; INFO [2020-10-21 02:08:05] Using svd initialization.
#&gt; INFO [2020-10-21 02:08:05] Done initializing.
#&gt; INFO [2020-10-21 02:08:05] Beginning AdaptiveImpute (max 10 iterations).
#&gt; INFO [2020-10-21 02:08:05] Checking convergence every 1 iteration(s).
#&gt; INFO [2020-10-21 02:08:05] Iter 1 complete. delta = 0.214455844482967, alpha = 7.19872761929092
#&gt; INFO [2020-10-21 02:08:05] Iter 2 complete. delta = 0.0655816579961252, alpha = 6.64450388191785
#&gt; INFO [2020-10-21 02:08:06] Iter 3 complete. delta = 0.0282828497742711, alpha = 6.29817854147802
#&gt; INFO [2020-10-21 02:08:06] Iter 4 complete. delta = 0.0149131921561725, alpha = 6.06364670460596
#&gt; INFO [2020-10-21 02:08:06] Iter 5 complete. delta = 0.00890970590501811, alpha = 5.89548036092589
#&gt; INFO [2020-10-21 02:08:06] Iter 6 complete. delta = 0.00579959384483573, alpha = 5.76959308559485
#&gt; INFO [2020-10-21 02:08:06] Iter 7 complete. delta = 0.0040222915648417, alpha = 5.67204772446829
#&gt; INFO [2020-10-21 02:08:07] Iter 8 complete. delta = 0.00293049425043196, alpha = 5.59426170122
#&gt; INFO [2020-10-21 02:08:07] Iter 9 complete. delta = 0.00222093116373994, alpha = 5.5307039336318
#&gt; INFO [2020-10-21 02:08:07] Iter 10 complete. delta = 0.00173822964715284, alpha = 5.47768100920203</div><div class='output co'>#&gt; <span class='warning'>Warning: </span>
#&gt; <span class='warning'>Reached maximum allowed iterations. Returning early.</span></div><div class='input'>
<span class='co'>### Exact AdaptiveInitialize initialization ---------------------------------</span>

<span class='va'>mf2</span> <span class='op'>&lt;-</span> <span class='fu'>citation_impute</span><span class='op'>(</span>
  <span class='va'>A</span>,
  rank <span class='op'>=</span> <span class='fl'>3L</span>,
  max_iter <span class='op'>=</span> <span class='fl'>10L</span>,
  initialization <span class='op'>=</span> <span class='st'>"adaptive-initialize"</span>
<span class='op'>)</span>
</div><div class='output co'>#&gt; INFO [2020-10-21 02:08:07] Matrix has 1000 non-zero elements, 510 in the upper triangle (including the diagonal), and 490 in the strict lower triangle.
#&gt; INFO [2020-10-21 02:08:07] Using adaptive-initialize initialization.
#&gt; INFO [2020-10-21 02:08:07] Beginning AdaptiveInitialize.
#&gt; INFO [2020-10-21 02:08:07] p_hat = 0.5341, non-zero entries = 1000, total entries = 10000
#&gt; INFO [2020-10-21 02:08:07] Calculating nuclear norm (slow step). Using exact method.
#&gt; INFO [2020-10-21 02:08:07] Computation complete, alpha = 6.43272360063481
#&gt; INFO [2020-10-21 02:08:07] lambda_hat = 19.5542188962643, 8.86806066342759, 8.6815774967917
#&gt; INFO [2020-10-21 02:08:07] Done initializing.
#&gt; INFO [2020-10-21 02:08:07] Beginning AdaptiveImpute (max 10 iterations).
#&gt; INFO [2020-10-21 02:08:07] Checking convergence every 1 iteration(s).
#&gt; INFO [2020-10-21 02:08:07] Iter 1 complete. delta = 0.107094385252634, alpha = 6.66993591988108
#&gt; INFO [2020-10-21 02:08:08] Iter 2 complete. delta = 0.0279517637430547, alpha = 6.30339393286254
#&gt; INFO [2020-10-21 02:08:08] Iter 3 complete. delta = 0.0150626880745451, alpha = 6.06584387384967
#&gt; INFO [2020-10-21 02:08:08] Iter 4 complete. delta = 0.00905399018631845, alpha = 5.89497466377753
#&gt; INFO [2020-10-21 02:08:08] Iter 5 complete. delta = 0.00589202079182546, alpha = 5.76696989181021
#&gt; INFO [2020-10-21 02:08:08] Iter 6 complete. delta = 0.00407714705762582, alpha = 5.66788203108073
#&gt; INFO [2020-10-21 02:08:09] Iter 7 complete. delta = 0.00296236276281234, alpha = 5.58899995835211
#&gt; INFO [2020-10-21 02:08:09] Iter 8 complete. delta = 0.00223929627619432, alpha = 5.524665682593
#&gt; INFO [2020-10-21 02:08:09] Iter 9 complete. delta = 0.00174875795612436, alpha = 5.47108714032427
#&gt; INFO [2020-10-21 02:08:09] Iter 10 complete. delta = 0.00140314681717488, alpha = 5.42565281799271</div><div class='output co'>#&gt; <span class='warning'>Warning: </span>
#&gt; <span class='warning'>Reached maximum allowed iterations. Returning early.</span></div><div class='input'>
<span class='co'>### Approximate AdaptiveInitialize initialization ---------------------------</span>

<span class='va'>mf3</span> <span class='op'>&lt;-</span> <span class='fu'>citation_impute</span><span class='op'>(</span>
  <span class='va'>A</span>,
  rank <span class='op'>=</span> <span class='fl'>3L</span>,
  max_iter <span class='op'>=</span> <span class='fl'>10L</span>,
  initialization <span class='op'>=</span> <span class='st'>"approximate"</span>,
  additional <span class='op'>=</span> <span class='fl'>5L</span>
<span class='op'>)</span>
</div><div class='output co'>#&gt; INFO [2020-10-21 02:08:09] Matrix has 1000 non-zero elements, 510 in the upper triangle (including the diagonal), and 490 in the strict lower triangle.
#&gt; INFO [2020-10-21 02:08:09] Using approximate initialization.
#&gt; INFO [2020-10-21 02:08:09] Beginning AdaptiveInitialize.
#&gt; INFO [2020-10-21 02:08:09] p_hat = 0.5341, non-zero entries = 1000, total entries = 10000
#&gt; INFO [2020-10-21 02:08:09] Calculating nuclear norm (slow step). Using approximate method.
#&gt; INFO [2020-10-21 02:08:09] Approximating alpha using rank 8 approximation.
#&gt; INFO [2020-10-21 02:08:09] Computation complete, alpha = 1.18127864248873
#&gt; INFO [2020-10-21 02:08:09] lambda_hat = 20.0194061721633, 9.85147942053702, 9.68395243048171
#&gt; INFO [2020-10-21 02:08:09] Done initializing.
#&gt; INFO [2020-10-21 02:08:09] Beginning AdaptiveImpute (max 10 iterations).
#&gt; INFO [2020-10-21 02:08:09] Checking convergence every 1 iteration(s).
#&gt; INFO [2020-10-21 02:08:10] Iter 1 complete. delta = 0.111048751408125, alpha = 6.63225678210305
#&gt; INFO [2020-10-21 02:08:10] Iter 2 complete. delta = 0.0257212887841839, alpha = 6.27770401359615
#&gt; INFO [2020-10-21 02:08:10] Iter 3 complete. delta = 0.0141298120405171, alpha = 6.05039979385688
#&gt; INFO [2020-10-21 02:08:10] Iter 4 complete. delta = 0.00861674757582726, alpha = 5.88577337685571
#&gt; INFO [2020-10-21 02:08:10] Iter 5 complete. delta = 0.00566189321294998, alpha = 5.76178252193578
#&gt; INFO [2020-10-21 02:08:11] Iter 6 complete. delta = 0.00394538779805784, alpha = 5.66540633961094
#&gt; INFO [2020-10-21 02:08:11] Iter 7 complete. delta = 0.00288225329574759, alpha = 5.58842506392507
#&gt; INFO [2020-10-21 02:08:11] Iter 8 complete. delta = 0.00218847687103855, alpha = 5.52545993076456
#&gt; INFO [2020-10-21 02:08:11] Iter 9 complete. delta = 0.00171557083514344, alpha = 5.47288743772458
#&gt; INFO [2020-10-21 02:08:11] Iter 10 complete. delta = 0.00138108359531644, alpha = 5.42820297945485</div><div class='output co'>#&gt; <span class='warning'>Warning: </span>
#&gt; <span class='warning'>Reached maximum allowed iterations. Returning early.</span></div><div class='input'>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by <a href='https://alexpghayes.com'>Alex Hayes</a>, Juhee Cho, Donggyu Kim, <a href='http://pages.stat.wisc.edu/~karlrohe/'>Karl Rohe</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


