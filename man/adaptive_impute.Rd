% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adaptive-impute.R, R/adaptive-initialize.R,
%   R/citation-impute.R
\name{adaptive_impute}
\alias{adaptive_impute}
\alias{adaptive_impute.sparseMatrix}
\alias{adaptive_impute.LRMF}
\alias{adaptive_initialize.sparseMatrix}
\alias{citation_impute.sparseMatrix}
\alias{citation_impute.LRMF}
\title{AdaptiveImpute}
\usage{
adaptive_impute(
  X,
  rank,
  ...,
  initialization = c("svd", "adaptive-initialize"),
  max_iter = 200L,
  check_interval = 1L,
  epsilon = 1e-07
)

\method{adaptive_impute}{sparseMatrix}(X, rank, initialization = c("svd", "adaptive-initialize"), ...)

\method{adaptive_impute}{LRMF}(
  mf,
  X,
  ...,
  epsilon = 1e-07,
  max_iter = 200L,
  check_interval = 1L,
  verbose = FALSE
)

\method{adaptive_initialize}{sparseMatrix}(X, rank, p_hat = NULL, ...)

\method{citation_impute}{sparseMatrix}(X, rank, initialization = c("svd", "adaptive-initialize"), ...)

\method{citation_impute}{LRMF}(
  mf,
  X,
  ...,
  epsilon = 1e-07,
  max_iter = 200L,
  check_interval = 1L,
  verbose = FALSE
)
}
\arguments{
\item{X}{A sparse matrix of \code{\link[Matrix:sparseMatrix]{Matrix::sparseMatrix()}} class.}

\item{rank}{Desired rank (integer) to use in the low rank approximation.}

\item{...}{Unused additional arguments.}

\item{initialization}{How to initialize the low rank approximation.
Options are:
\itemize{
\item \code{"svd"} (default). In the initialization step, this treats
unobserved values as zeroes.
\item \code{"adaptive-initialize"}. In the initialization step, this treats
unobserved values as actually unobserved. However, the current
\code{AdaptiveInitialize} implementation relies on dense matrix
computations that are only suitable for relatively small matrices.
}

Note that initialization matters as \code{AdaptiveImpute} optimizes
a non-convex objective. The current theory shows that initializing
with \code{AdaptiveInitialize} leads to a consistent estimator, but it
isn't know if this is the case for SVD initialization. Empirically
we have found that SVD initialization works well nonetheless.}

\item{max_iter}{Maximum number of iterations to perform (integer). Defaults
to \code{200L}. In practice 10 or so iterations will get you a decent
approximation to use in exploratory analysis, and and 50-100 will get
you most of the way to convergence.}

\item{check_interval}{Integer specifying how often to perform convergence
checks. Defaults to \code{1L}. In practice, check for convergence requires
a norm calculation that is expensive for large matrices and decreasing
the frequency of convergence checks will reduce computation time.}

\item{epsilon}{Convergence criteria, measured in terms of relative change
in Frobenius norm of the full imputed matrix. Defaults to \code{1e-7}.}
}
\value{
A low rank matrix factorization represented by an
\code{LRMF} object. See \code{\link[LRMF3:mf]{LRMF3::mf()}} for details.
}
\description{
An implementation of the \code{AdaptiveImpute} algorithm for matrix completion
for sparse matrices.
}
\examples{

mf <- adaptive_impute(ml100k, rank = 3L, max_iter = 20L)
# mf

# build a rank-5 approximation only for
# observed elements of ml100k

predict(mf, ml100k)


# estimate the in-sample reconstruction mse

R <- resid(mf, ml100k)
norm(R, type = "F") / nnzero(ml100k)


mf2 <- adaptive_impute(
  ml100k,
  rank = 3L,
  max_iter = 20L,
  initialization = "adaptive-initialize"
)

# mf2

R2 <- resid(mf2, ml100k)
norm(R2, type = "F") / nnzero(ml100k)

}
